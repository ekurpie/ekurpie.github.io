# -*- coding: utf-8 -*-
"""Random_forest_new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SPmlFerf7YxYSudUF4G-rUf3TVge7SEq
"""

#@title Imports & Set Path


import pandas_profiling
import pandas as pd
from random import randint
import numpy as np
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt

import keras
from keras.models import Sequential, Model
from keras.models import load_model
from keras.layers import Dense, LSTM
from keras.layers import Add, Average 
from keras.layers import Dropout, Activation, Input, Flatten
from keras.layers import TimeDistributed, Bidirectional
from keras import optimizers
from keras import regularizers
from keras.utils.np_utils import to_categorical

from sklearn.model_selection import train_test_split





path = 'Data/' #add the path of your data

#@title reading from google colab drive 
from google.colab import drive 
drive.mount('/content/gdrive')

path = '/content/gdrive/My Drive/ChallengeUP-master/ChallengeUP-master/Data/'

base = pd.read_csv(path + 'CompleteDataSet_training_competition_fixed.csv')

base.head()

base.describe()

base.info(verbose=True)

base.shape

base.isnull().sum()

base['TimeStamps'] = pd.to_datetime(base['TimeStamps'])

abs(base.corr()["Tag"].sort_values(ascending=False))

# base.profile_report()

Falling1 = (base["Tag"].values==1).sum()
Falling2 = (base["Tag"].values==2).sum()
Falling3 = (base["Tag"].values==3).sum()
Falling4 = (base["Tag"].values==4).sum()
Falling5 = (base["Tag"].values==5).sum()
Walking = (base["Tag"].values==6).sum()
Standing = (base["Tag"].values==7).sum()
Sitting = (base["Tag"].values==8).sum()
Object = (base["Tag"].values==9).sum()
Jumping = (base["Tag"].values==10).sum()
Laying = (base["Tag"].values==11).sum()
Other = (base["Tag"].values==20).sum()

frequency_dict = {"Fal1": Falling1,
                  "Fal2": Falling2,
                  "Fal3": Falling3,
                  "Fal4": Falling4,
                  "Fal5": Falling5,
                  "Walk": Walking,
                  "Stand": Standing,
                  "Sit": Sitting,
                  "Pick": Object,
                  "Jump": Jumping,
                  "Lay": Laying,
                  "Other" : Other}

frequency = pd.DataFrame(list(frequency_dict.items()),columns=["Activity","Count"])
frequency.head(12)

y = base["Tag"]
y = pd.DataFrame(y,columns=["Tag"])

x = base.drop(["Tag","TimeStamps","Unnamed: 0"],axis=1)

x.head()

x.info(verbose=True)

y.head()

x.shape

y.shape

from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.naive_bayes import MultinomialNB

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score
from sklearn.metrics import confusion_matrix,classification_report

from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler

def normalize_(x):
  scaler=StandardScaler()
  return scaler.fit_transform(x)

x.shape

y.shape

x.head()

y.head()

# Random Forest

clf = RandomForestClassifier(
    n_estimators=100,
    criterion='gini',
    max_depth=5,
    min_samples_split=2,
    min_samples_leaf=1,
    min_weight_fraction_leaf=0.0,
    max_features='auto',
    max_leaf_nodes=None,
    min_impurity_decrease=0.0,
    min_impurity_split=None,
    bootstrap=True,
    oob_score=False,
    n_jobs=-1,
    random_state=0,
    verbose=0,
    warm_start=False,
    class_weight='balanced'
)



algos_name=['RandomForest']
accuracy = []
precision = []
recall = []
f1 = []
result=pd.DataFrame(columns=['AccuracyScore','PrecisionScore','RecallScore','f1_Score'],index=algos_name)
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42)
clf.fit(x_train,y_train)

predict = clf.predict(x_test)

accuracy.append(accuracy_score(y_test,predict))
precision.append(precision_score(y_test,predict,average='weighted'))
recall.append(recall_score(y_test,predict,average='weighted'))
f1.append(f1_score(y_test,predict,average='weighted'))

result.AccuracyScore=accuracy
result.PrecisionScore=precision
result.RecallScore=recall
result.f1_Score=f1

result.sort_values('f1_Score',ascending=False)

importances = clf.feature_importances_

for i,v in enumerate(importances):
	print('Feature: %0d, Score: %.5f' % (i,v))

path = '/content/gdrive/My Drive/ChallengeUP-master/ChallengeUP-master/Data/'

test = pd.read_csv(path + 'CompleteDataSet_testing_competition_fixed.csv')

test.head()

test.info()

test_time = test

test = test.drop(["TimeStamps"],axis=1)

test.head()

test = test.drop(["Unnamed: 0"],axis=1)

# predictions = classification_(X_train,Y_train,prediction = test_df)
predictions = clf.predict(test)

predictions

# submission = pd.DataFrame(predictions, columns=["Tag_1" ,	"Tag_2" ,	"Tag_3" ,	"Tag_4 ",	"Tag_5 ","Tag_6","Tag_7" ,"Tag_8" ,"Tag_9 ","Tag_10","Tag_11" ,"Tag_20"]) #for dummies
submission = pd.DataFrame(predictions, columns=["Target"])
submission.head()

test_time

test_time = test_time["TimeStamps"]

test_time

# base['TimeStamps'] = pd.to_datetime(base['TimeStamps'])

timestamps = pd.DataFrame(test_time, columns=["TimeStamps"])
timestamps["TimeStamps"] = pd.to_datetime(timestamps["TimeStamps"])
# timestamps = timestamps.drop(timestamps.index[0])
timestamps = timestamps.reset_index()
timestamps = timestamps.drop(["index"],axis=1)
timestamps
timestamps2 = timestamps['TimeStamps'].apply(
      lambda x: x.replace(microsecond=0))

timestamps2 = pd.DataFrame(timestamps2,columns=["TimeStamps"])
timestamps2

submission.info(verbose=True)

submission_combined = timestamps2.join(submission.astype(int))
submission_combined



submission_combined.head(20)

# test4 = submission_combined.loc[submission_combined["TimeStamps"] == test3 ].mode()
# test4.head()

submission_combined = submission_combined.groupby(by='TimeStamps', as_index=False)['Target'].agg(pd.Series.mode, )

submission_combined.head()

submission_combined['IsArray'] = submission_combined.Target.apply(lambda x: isinstance(x,(list,pd.core.series.Series,np.ndarray)))

submission_combined = submission_combined.loc[submission_combined.IsArray == False].loc[:, ['TimeStamps','Target']]

submission_combined.Target = pd.to_numeric(submission_combined.Target, downcast='integer')

submission_combined.head()

submission_combined.columns = ["timestamp","target"]

submission_combined.head()

# @title Submission File

!pip install -U -q PyDrive
from google.colab import auth
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from oauth2client.client import GoogleCredentials
import datetime

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
driveWriter = GoogleDrive(gauth)

folder_id = '1El1JO73c9fdMmqnVkB-8dryE47oyoJXP'
file_title = 'test-results' + "_New3" + '.csv' 

submission_file = driveWriter.CreateFile({
    'title': file_title,
    'parents': [{'kind': 'drive#fileLink', 'id': folder_id}]
})

submission_file.SetContentString(
    submission_combined.to_csv(
        index=False, columns=['timestamp', 'target']
    )
)

submission_file.Upload()