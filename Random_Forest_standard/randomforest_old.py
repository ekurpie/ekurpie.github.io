# -*- coding: utf-8 -*-
"""RandomForest_old.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ApEQlonwOdaXoJYfWgDyK3lmn-m-RIT1
"""

#@title Imports & Set Path
!pip3 install pandas_profiling --upgrade

import pandas_profiling
import pandas as pd
from random import randint
import numpy as np
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt

import keras
from keras.models import Sequential, Model
from keras.models import load_model
from keras.layers import Dense, LSTM
from keras.layers import Add, Average 
from keras.layers import Dropout, Activation, Input, Flatten
from keras.layers import TimeDistributed, Bidirectional
from keras import optimizers
from keras import regularizers
from keras.utils.np_utils import to_categorical

from sklearn.model_selection import train_test_split



path = 'Data/' #add the path of your data

#@title reading from google colab drive 
from google.colab import drive 
drive.mount('/content/gdrive')

path = '/content/gdrive/My Drive/ChallengeUP-master/ChallengeUP-master/Data/'

base = pd.read_csv(path + 'CompleteDataSet_training_competition.csv')

base.head()

base.describe()

base.shape

base.isnull().sum()

base['TimeStamps'] = pd.to_datetime(base['TimeStamps'])

abs(base.corr()["Tag"].sort_values(ascending=False))

# base.profile_report()

Falling1 = (base["Tag"].values==1).sum()
Falling2 = (base["Tag"].values==2).sum()
Falling3 = (base["Tag"].values==3).sum()
Falling4 = (base["Tag"].values==4).sum()
Falling5 = (base["Tag"].values==5).sum()
Walking = (base["Tag"].values==6).sum()
Standing = (base["Tag"].values==7).sum()
Sitting = (base["Tag"].values==8).sum()
Object = (base["Tag"].values==9).sum()
Jumping = (base["Tag"].values==10).sum()
Laying = (base["Tag"].values==11).sum()
Other = (base["Tag"].values==20).sum()

frequency_dict = {"Fall1": Falling1,
                  "Fall2": Falling2,
                  "Fall3": Falling3,
                  "Fall4": Falling4,
                  "Fall5": Falling5,
                  "Walk": Walking,
                  "Stand": Standing,
                  "Sit": Sitting,
                  "Pick": Object,
                  "Jump": Jumping,
                  "Lay": Laying,
                  "NA" : Other}

frequency = pd.DataFrame(list(frequency_dict.items()),columns=["Activity","Count"])
frequency.head(12)

ax = sns.barplot(x="Activity",y="Count", data=frequency, palette="flare")

x = base.drop(["TimeStamps","Tag","Subject","Trial","Activity"],axis=1)

x

y = base["Tag"]
y = pd.DataFrame(y,columns=["Tag"])

x.shape

x.info()

columns2 = [col for col in x.columns]
columns2

# x = x.drop(["Infrared1","Infrared2","Infrared3","Infrared4","Infrared5","Infrared6","AnkleLuminosity illuminance ", "RightPocketLuminosity illuminance", "BeltLuminosity illuminance", "NeckLuminosity illuminance","WristLuminosity illuminance", "BrainSensor"],axis=1)
x = x.drop(["Infrared1","Infrared2","Infrared3","Infrared4","Infrared5","Infrared6","AnkleLuminosity illuminance ", "RightPocketLuminosity illuminance", "BeltLuminosity illuminance", "NeckLuminosity illuminance","WristLuminosity illuminance", "BrainSensor"],axis=1)

x.head()

# from imblearn.over_sampling import SMOTE
# from sklearn.utils import class_weight
# smote = SMOTE()

X_train, Y_train = smote.fit_resample(x,y)

# X_train, Y_train = x.values,y.values # for without smote

Y_train

columns = [col for col in x.columns]
columns

X_train.shape

Y_train.shape

X2 = pd.DataFrame(X_train, columns=[col for col in columns])

Y2 = pd.DataFrame(Y_train,columns=["Tag"])

Y2.head()

Y2.shape

Y2.head()

Y_train[1]

X2.head()

Y2.head()

X2.info()

X2["Tag"] = Y2["Tag"]

X2.head()

X2.info()

Falling1 = (X2["Tag"].values==1).sum()
Falling2 = (X2["Tag"].values==2).sum()
Falling3 = (X2["Tag"].values==3).sum()
Falling4 = (X2["Tag"].values==4).sum()
Falling5 = (X2["Tag"].values==5).sum()
Walking = (X2["Tag"].values==6).sum()
Standing = (X2["Tag"].values==7).sum()
Sitting = (X2["Tag"].values==8).sum()
Object = (X2["Tag"].values==9).sum()
Jumping = (X2["Tag"].values==10).sum()
Laying = (X2["Tag"].values==11).sum()
Other = (X2["Tag"].values==20).sum()

frequency_dict = {"Falling1": Falling1,
                  "Falling2": Falling2,
                  "Falling3": Falling3,
                  "Falling4": Falling4,
                  "Falling5": Falling5,
                  "Walking": Walking,
                  "Standing": Standing,
                  "Sitting": Sitting,
                  "Object": Object,
                  "Jumping": Jumping,
                  "Laying": Laying,
                  "Other" : Other}

frequency = pd.DataFrame(list(frequency_dict.items()),columns=["Activity","Count"])
frequency.head(12)

ax = sns.barplot(x="Activity",y="Count", data=frequency)

X2.head(50)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.naive_bayes import MultinomialNB

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score
from sklearn.metrics import confusion_matrix,classification_report

from sklearn import preprocessing

def normalize_(x):
  from sklearn.preprocessing import MinMaxScaler
  scaler=MinMaxScaler()
  return scaler.fit_transform(x)

X2.info()

X_train = X2.drop(["Tag"],axis=1)
X_train.head()

X_train = X_train.values
X_train

# Y2 = pd.get_dummies(Y2,columns=["Tag"])

Y2.tail()

Y_train = Y2.values
Y_train

Y_train[0]

X_train = normalize_(X_train)

X_train

def classification_(x,y,prediction=None):
    
    
    #g=GaussianNB()
    #b=BernoulliNB()
    # k=KNeighborsClassifier()
    # svc=SVC()
    # d=DecisionTreeClassifier()
    # log=LogisticRegression()
    # gbc=GradientBoostingClassifier()
    # mn=MultinomialNB()
    rf=RandomForestClassifier()
    # ab=AdaBoostClassifier()
    
    # algos=[k,svc,d,log,gbc,mn,rf,ab]
    algos=[rf]
    # algos_name=['KNeigbors','SVC','DecisionTree','LogisticRegr','GradientBoosting','Multinominal','RandomForest','AdaBoost']
    algos_name=['RandomForest']
    accuracy = []
    precision = []
    recall = []
    f1 = []
   
    result=pd.DataFrame(columns=['AccuracyScore','PrecisionScore','RecallScore','f1_Score'],index=algos_name)

    x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42)

    for i in algos:
        
        predict=i.fit(x_train,y_train).predict(x_test)
        
        accuracy.append(accuracy_score(y_test,predict))
        precision.append(precision_score(y_test,predict,average='weighted'))
        recall.append(recall_score(y_test,predict,average='weighted'))
        f1.append(f1_score(y_test,predict,average='weighted'))
      
    result.AccuracyScore=accuracy
    result.PrecisionScore=precision
    result.RecallScore=recall
    result.f1_Score=f1
    if len(prediction) > 0:
      print(result.sort_values('f1_Score',ascending=False))
      predict = rf.predict(prediction)
      return predict
    else:
      return result.sort_values('f1_Score',ascending=False)

from sklearn.model_selection import KFold
from sklearn.model_selection import RandomizedSearchCV

n_estimators = [int(x) for x in np.linspace(start = 50, stop = 2000, num = 10)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)
min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
bootstrap = [True, False]

clf = RandomForestClassifier()


random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}

rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=1, random_state=42, n_jobs = -1)

rf_random.fit(X_train, Y_train)

rf_random.best_params

algos_name=['RandomForest']
accuracy = []
precision = []
recall = []
f1 = []
result=pd.DataFrame(columns=['AccuracyScore','PrecisionScore','RecallScore','f1_Score'],index=algos_name)
x_train,x_test,y_train,y_test=train_test_split(X_train,Y_train,random_state=42)
clf.fit(x_train,y_train)

predict = clf.predict(x_test)

accuracy.append(accuracy_score(y_test,predict))
precision.append(precision_score(y_test,predict,average='weighted'))
recall.append(recall_score(y_test,predict,average='weighted'))
f1.append(f1_score(y_test,predict,average='weighted'))

result.AccuracyScore=accuracy
result.PrecisionScore=precision
result.RecallScore=recall
result.f1_Score=f1

result.sort_values('f1_Score',ascending=False)

path = '/content/gdrive/My Drive/ChallengeUP-master/ChallengeUP-master/Data/'

test = pd.read_csv(path + 'CompleteDataSet_testing_competition.csv')

test.head()

test.info()

test_time = test

test = test.drop(["TimeStamps"],axis=1)

test.head()

# df.drop(df.index[2])
test = test.drop(test.index[0])
test2 = test.values
test2 = test2.astype("float")
test2

# X2 = pd.DataFrame(X_train, columns=[col for col in columns])

test_df = pd.DataFrame(test2, columns=[col for col in columns2] )
test_df.head()

test_df = test_df.drop(["Infrared1","Infrared2","Infrared3","Infrared4","Infrared5","Infrared6","AnkleLuminosity illuminance ", "RightPocketLuminosity illuminance", "BeltLuminosity illuminance", "NeckLuminosity illuminance","WristLuminosity illuminance", "BrainSensor"],axis=1)

test_df.info()

test_df =  normalize_(test_df.values)

test_df[0]

predictions = classification_(X_train,Y_train,prediction = test_df)

predictions

# submission = pd.DataFrame(predictions, columns=["Tag_1" ,	"Tag_2" ,	"Tag_3" ,	"Tag_4 ",	"Tag_5 ","Tag_6","Tag_7" ,"Tag_8" ,"Tag_9 ","Tag_10","Tag_11" ,"Tag_20"]) #for dummies
submission = pd.DataFrame(predictions, columns=["Target"])
submission.head()

test_time

test_time = test_time["TimeStamps"]

test_time

test_time = test_time[1:]
test_time

# base['TimeStamps'] = pd.to_datetime(base['TimeStamps'])

timestamps = pd.DataFrame(test_time, columns=["TimeStamps"])
timestamps["TimeStamps"] = pd.to_datetime(timestamps["TimeStamps"])
# timestamps = timestamps.drop(timestamps.index[0])
timestamps = timestamps.reset_index()
timestamps = timestamps.drop(["index"],axis=1)
timestamps
timestamps2 = timestamps['TimeStamps'].apply(
      lambda x: x.replace(microsecond=0))

timestamps2 = pd.DataFrame(timestamps2,columns=["TimeStamps"])
timestamps2

submission_combined = timestamps2.join(submission.astype(int))
submission_combined

# test4 = submission_combined.loc[submission_combined["TimeStamps"] == test3 ].mode()
# test4.head()

#Trying to figure out how to use the unique timestamps and mode to get the predicted target at this point
# df.loc[df['column_name'] == some_value]

test = submission_combined["TimeStamps"].unique()
appender = pd.DataFrame(columns=["TimeStamps","Target"])
appender.head()

test

test2 = []

for element in test:
  test2.append(submission_combined.loc[submission_combined["TimeStamps"] == element].mode())

appender

for element in range(len(test2)):
  appender = appender.append(test2[element])

appender = appender.reset_index()

appender.head()

appender = appender.drop(["index"],axis = 1)

appender = appender.dropna()
appender = appender.reset_index()

appender = appender.drop(["index"],axis=1)
appender

final_results = appender
final_results.columns=["timestamp","target"]
final_results.head()

# @title Submission File

!pip install -U -q PyDrive
from google.colab import auth
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from oauth2client.client import GoogleCredentials
import datetime

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
driveWriter = GoogleDrive(gauth)

folder_id = '1El1JO73c9fdMmqnVkB-8dryE47oyoJXP'
file_title = 'test-results' + str(datetime.datetime.now()) + "RF_ML" + '.csv' 

submission_file = driveWriter.CreateFile({
    'title': file_title,
    'parents': [{'kind': 'drive#fileLink', 'id': folder_id}]
})

submission_file.SetContentString(
    final_results.to_csv(
        index=False, columns=['timestamp', 'target']
    )
)

submission_file.Upload()